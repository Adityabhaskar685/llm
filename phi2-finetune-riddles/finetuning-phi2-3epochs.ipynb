{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Finetuning Phi2 on custom riddle dataset","metadata":{}},{"cell_type":"code","source":"# packages \n!pip install -U accelerate peft transformers einops datasets bitsandbytes --q","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:40:27.870610Z","iopub.execute_input":"2024-02-04T09:40:27.870957Z","iopub.status.idle":"2024-02-04T09:40:59.386118Z","shell.execute_reply.started":"2024-02-04T09:40:27.870920Z","shell.execute_reply":"2024-02-04T09:40:59.385056Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ns3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip freeze | egrep \"accelerate|peft|transformers|einops|datasets|^torch=|bitsandbytes\" ","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:40:59.388180Z","iopub.execute_input":"2024-02-04T09:40:59.388522Z","iopub.status.idle":"2024-02-04T09:41:02.085603Z","shell.execute_reply.started":"2024-02-04T09:40:59.388496Z","shell.execute_reply":"2024-02-04T09:41:02.084670Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"accelerate==0.26.1\nbitsandbytes==0.42.0\ndatasets==2.16.1\neinops==0.7.0\npeft==0.8.2\ntensorflow-datasets==4.9.4\ntransformers==4.37.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# seed \nfrom transformers import set_seed\nset_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:41:02.086948Z","iopub.execute_input":"2024-02-04T09:41:02.087246Z","iopub.status.idle":"2024-02-04T09:41:20.590014Z","shell.execute_reply.started":"2024-02-04T09:41:02.087219Z","shell.execute_reply":"2024-02-04T09:41:20.589123Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-02-04 09:41:10.371806: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-04 09:41:10.371906: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-04 09:41:10.534672: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model and Tokenizer\n\n### Loading Model in 4bit","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, BitsAndBytesConfig\n\n# model\nmodel_path = 'microsoft/phi-2'\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_path,\n    device_map = 'auto',\n    quantization_config = BitsAndBytesConfig(\n        load_in_4bit =True,\n        bnb_4bit_compute_dtype = torch.bfloat16,\n        bnb_4bit_quant_type = 'nf4'\n    ),\n    torch_dtype = torch.bfloat16,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:41:20.592645Z","iopub.execute_input":"2024-02-04T09:41:20.593621Z","iopub.status.idle":"2024-02-04T09:41:58.463181Z","shell.execute_reply.started":"2024-02-04T09:41:20.593587Z","shell.execute_reply":"2024-02-04T09:41:58.462202Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/863 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b94d2dd2d064ffbb7d770c6583e4ead"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55a5158080944e87a652276ee0a817df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46a6de683b584d2e95d3dce7e38180e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39bde0a8788d4ce89e762ceffc27bc9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c813fe69de4d4664a08a35c3f2036ada"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a38e5ee8ed954acf84d26bfcb87415fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc08225031ce4773a075f83cedd0dba8"}},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:41:58.464402Z","iopub.execute_input":"2024-02-04T09:41:58.464733Z","iopub.status.idle":"2024-02-04T09:41:58.473909Z","shell.execute_reply.started":"2024-02-04T09:41:58.464707Z","shell.execute_reply":"2024-02-04T09:41:58.473028Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"PhiForCausalLM(\n  (model): PhiModel(\n    (embed_tokens): Embedding(51200, 2560)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x PhiDecoderLayer(\n        (self_attn): PhiAttention(\n          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n          (rotary_emb): PhiRotaryEmbedding()\n        )\n        (mlp): PhiMLP(\n          (activation_fn): NewGELUActivation()\n          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n        )\n        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Tokenizer","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_path, use_fast = False)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:41:58.475119Z","iopub.execute_input":"2024-02-04T09:41:58.475674Z","iopub.status.idle":"2024-02-04T09:42:03.229227Z","shell.execute_reply.started":"2024-02-04T09:41:58.475642Z","shell.execute_reply":"2024-02-04T09:42:03.228376Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d942a9e9fa1f45929090477093a0db87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6782591461544d4bad8a5ff263feb0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"578b5434557948e0b7dda508b037c0dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d6196aeeba9454983270e28679172b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d84929188fb4f8b921e4d485faaed7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74fefded56434a2ebf2f322c039d9dab"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"len(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:03.230338Z","iopub.execute_input":"2024-02-04T09:42:03.230621Z","iopub.status.idle":"2024-02-04T09:42:03.240090Z","shell.execute_reply.started":"2024-02-04T09:42:03.230596Z","shell.execute_reply":"2024-02-04T09:42:03.239236Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"50295"},"metadata":{}}]},{"cell_type":"markdown","source":"### Add ChatML tokens to tokenizer","metadata":{}},{"cell_type":"code","source":"tokenizer.add_tokens(['<|im_start|>', \"<PAD>\"])\ntokenizer.pad_token = '<PAD>'\ntokenizer.add_special_tokens(dict(eos_token = '<|im_end|>'))\nmodel.config.eos_token_id = tokenizer.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:03.241295Z","iopub.execute_input":"2024-02-04T09:42:03.241653Z","iopub.status.idle":"2024-02-04T09:42:03.255196Z","shell.execute_reply.started":"2024-02-04T09:42:03.241622Z","shell.execute_reply":"2024-02-04T09:42:03.254496Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Note: there is no need to rezise the token embeddings, phi-2 already has embeddings sized for additional tokens. The model's vocab. size is 51200, this means you can add ~700 tokens to the tokenizer without having to resize the embeddings.","metadata":{}},{"cell_type":"code","source":"model.model.embed_tokens","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:03.256304Z","iopub.execute_input":"2024-02-04T09:42:03.256602Z","iopub.status.idle":"2024-02-04T09:42:03.266850Z","shell.execute_reply.started":"2024-02-04T09:42:03.256578Z","shell.execute_reply":"2024-02-04T09:42:03.266067Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Embedding(51200, 2560)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Prepare LoRA adapters","metadata":{}},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n\nmodel = prepare_model_for_kbit_training(model, use_gradient_checkpointing = True)\n\nlora_config = LoraConfig(\n    r = 32,\n    lora_alpha = 32,\n    target_modules = ['q_proj','k_proj','v_proj','dense'],\n    modules_to_save = ['lm_head','embed_tokens'],\n    lora_dropout = 0.1,\n    bias = 'none',\n    task_type = 'CAUSAL_LM'\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.config.use_cache = False","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:03.271549Z","iopub.execute_input":"2024-02-04T09:42:03.271854Z","iopub.status.idle":"2024-02-04T09:42:03.806891Z","shell.execute_reply.started":"2024-02-04T09:42:03.271828Z","shell.execute_reply":"2024-02-04T09:42:03.806035Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Load and Preprocess dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset('Aditya685/riddles_improved_v2')\ndataset = dataset['train'].train_test_split(test_size =0.1)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:03.808121Z","iopub.execute_input":"2024-02-04T09:42:03.808445Z","iopub.status.idle":"2024-02-04T09:42:06.432345Z","shell.execute_reply.started":"2024-02-04T09:42:03.808419Z","shell.execute_reply":"2024-02-04T09:42:06.431584Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/313 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f48ee822183c41409ea9b900a32e4ad7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/578k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7719c2c745ac49d0859bc545b412a4f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/908 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7a2a568925a4032a196750388e8cce4"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:06.434120Z","iopub.execute_input":"2024-02-04T09:42:06.435641Z","iopub.status.idle":"2024-02-04T09:42:06.442752Z","shell.execute_reply.started":"2024-02-04T09:42:06.435440Z","shell.execute_reply":"2024-02-04T09:42:06.441858Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['number', 'messages'],\n        num_rows: 817\n    })\n    test: Dataset({\n        features: ['number', 'messages'],\n        num_rows: 91\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:06.443662Z","iopub.execute_input":"2024-02-04T09:42:06.443910Z","iopub.status.idle":"2024-02-04T09:42:06.457553Z","shell.execute_reply.started":"2024-02-04T09:42:06.443887Z","shell.execute_reply":"2024-02-04T09:42:06.456642Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'number': 142,\n 'messages': [\"A word of three letters long, which, spoken after 'how,' describes how a rabbit hops.\",\n  'The answer to this riddle is the word \"hop.\" When you say \"how a rabbit hops,\" the word that describes the way a rabbit moves in short bursts is \"hop.\" Therefore, the word that completes the sentence and follows \"how\" is \"hop.\"\\n\\nIf you have any questions about the answer or need further clarification, please let me know.',\n  \"So, 'hop' is the answer and it's how rabbits move? But, how do birds fly? What's the word that comes after 'how' for that?\",\n  'The word that comes after \"how\" to describe how birds fly is \"fly.\" Birds are able to move through the air by flapping their wings, which allows them to generate lift and stay aloft. The word \"fly\" is the verb that describes this action.\\n\\nSo, to summarize:\\n\\n* \"How a rabbit hops?\" - Answer: \"hop\"\\n* \"How a bird flies?\" - Answer: \"fly\"\\n\\nI hope this helps clarify any confusion. Let me know if you have any other questions!']}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Apply ChatML format and tokenize\n","metadata":{}},{"cell_type":"code","source":"import os\nfrom functools import partial\n\n# Format (ChatML) and tokenize dataset\ntemplates = [\n    '<|im_start|>assistant\\n{msg}<|im_end|>',\n    '<|im_start|>user\\n{msg}<|im_end|>'\n]\n\nIGNORE_INDEX = -100\n\ndef tokenize(input, max_length):\n    input_ids, attention_mask , labels = [], [], []\n    \n    for i , msg in enumerate(input['messages']):\n        isHuman = i%2 == 0\n        msg_chatml = templates[isHuman].format(msg = msg)\n        msg_tokenized = tokenizer(msg_chatml, truncation=False, add_special_tokens=False)\n\n        input_ids+= msg_tokenized['input_ids']\n        attention_mask+= msg_tokenized['attention_mask']\n        labels+= [IGNORE_INDEX] * len(msg_tokenized['input_ids']) if isHuman else msg_tokenized['input_ids']\n\n    return {\n        'input_ids' : input_ids[:max_length],\n        'attention_mask' : attention_mask[:max_length],\n        'labels': labels[:max_length]\n    }\n\n\n\ndataset_tokenized = dataset.map(\n    partial(tokenize, max_length = 1024), # max sample length 1024 tokens, enough for this dataset\n    batched = False,\n    num_proc = os.cpu_count(), # multithreaded\n    remove_columns = dataset['train'].column_names # don't need this anymore\n\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:06.458551Z","iopub.execute_input":"2024-02-04T09:42:06.458812Z","iopub.status.idle":"2024-02-04T09:42:13.777707Z","shell.execute_reply.started":"2024-02-04T09:42:06.458789Z","shell.execute_reply":"2024-02-04T09:42:13.776593Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/817 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24099aa3c96d4f93b8752bb9e73e69c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/91 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23b8f9b2b7bf41229711c7a95f8c7502"}},"metadata":{}}]},{"cell_type":"code","source":"dataset_tokenized","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:13.779409Z","iopub.execute_input":"2024-02-04T09:42:13.780323Z","iopub.status.idle":"2024-02-04T09:42:13.787139Z","shell.execute_reply.started":"2024-02-04T09:42:13.780280Z","shell.execute_reply":"2024-02-04T09:42:13.786109Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 817\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 91\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Sample size distribution\nimport matplotlib.pyplot as plt\n\ndata = [len(tok) for tok in (dataset_tokenized[\"train\"][\"input_ids\"]+dataset_tokenized[\"test\"][\"input_ids\"])] \nprint(f\"longest sample: {max(data)} tokens\")\n\nplt.hist(data, bins=10)  \nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:13.788333Z","iopub.execute_input":"2024-02-04T09:42:13.788639Z","iopub.status.idle":"2024-02-04T09:42:14.204372Z","shell.execute_reply.started":"2024-02-04T09:42:13.788613Z","shell.execute_reply":"2024-02-04T09:42:14.203502Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"longest sample: 878 tokens\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"### Define a collate function,train on answers only\n\n","metadata":{}},{"cell_type":"code","source":"# collate function - to transform list of dictionaries [ {input_ids: [123, ..]}, {.. ] to single batch dictionary { input_id}\n\ndef collate(elements):\n    tokens = [e['input_ids'] for e in elements]\n    tokens_maxlen = max([len(t) for t  in tokens])\n\n    for i, sample in enumerate(elements):\n        input_ids = sample['input_ids']\n        labels = sample['labels']\n        attention_mask = sample['attention_mask']\n\n        pad_len = tokens_maxlen - len(input_ids)\n\n        input_ids.extend(pad_len * [tokenizer.pad_token_id])\n        labels.extend(pad_len * [IGNORE_INDEX])\n        attention_mask.extend(pad_len * [0])\n\n    batch = {\n        'input_ids' : torch.tensor([e['input_ids'] for e in elements]),\n        'labels' : torch.tensor([e['labels'] for e in elements]),\n        'attention_mask' : torch.tensor([e['attention_mask'] for e in elements])\n\n    }\n\n    return batch\n","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:14.205593Z","iopub.execute_input":"2024-02-04T09:42:14.205873Z","iopub.status.idle":"2024-02-04T09:42:14.213886Z","shell.execute_reply.started":"2024-02-04T09:42:14.205849Z","shell.execute_reply":"2024-02-04T09:42:14.212929Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Train\n\n#### Set Hyperparameters","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n# dataset- specific parameters\nbs = 1 # batch size for training\nbs_eval = 16 # batch size for evaluation\nga_steps = 16 # gradient accumulation steps\nlr = 0.00002 # learning rate\n\nepochs = 3\n\nsteps_per_epoch = len(dataset_tokenized['train']) // (bs * ga_steps)\n\nargs = TrainingArguments(\n    output_dir=\"out\",\n    per_device_train_batch_size=bs,\n    per_device_eval_batch_size=bs_eval,\n    evaluation_strategy=\"steps\",\n    logging_steps=20,\n    eval_steps=steps_per_epoch//2,    # 2 evals per epoch\n    save_steps=steps_per_epoch,     # save once per epoch\n    gradient_accumulation_steps=ga_steps,\n    num_train_epochs=epochs,\n    lr_scheduler_type=\"constant\",\n    optim=\"paged_adamw_32bit\",      # val_loss will go nan with paged_adamw_8bit\n    learning_rate=lr,\n    group_by_length=False,\n    bf16=False,        \n    ddp_find_unused_parameters=False,\n)\n\ntrainer = Trainer(\n    model=model,\n    tokenizer=tokenizer,\n    args=args,\n    data_collator=collate,\n    train_dataset=dataset_tokenized[\"train\"],\n    eval_dataset=dataset_tokenized[\"test\"],\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:14.214954Z","iopub.execute_input":"2024-02-04T09:42:14.215221Z","iopub.status.idle":"2024-02-04T09:42:15.618424Z","shell.execute_reply.started":"2024-02-04T09:42:14.215192Z","shell.execute_reply":"2024-02-04T09:42:15.617629Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# wandb project\nimport wandb\nrun = wandb.init(\n    project = 'phi2',\n    name = 'testrunkaggle'\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:42:15.619861Z","iopub.execute_input":"2024-02-04T09:42:15.620535Z","iopub.status.idle":"2024-02-04T09:43:32.472082Z","shell.execute_reply.started":"2024-02-04T09:42:15.620498Z","shell.execute_reply":"2024-02-04T09:43:32.471284Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240204_094301-1447l8yp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/aditya685/phi2/runs/1447l8yp' target=\"_blank\">testrunkaggle</a></strong> to <a href='https://wandb.ai/aditya685/phi2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/aditya685/phi2' target=\"_blank\">https://wandb.ai/aditya685/phi2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/aditya685/phi2/runs/1447l8yp' target=\"_blank\">https://wandb.ai/aditya685/phi2/runs/1447l8yp</a>"},"metadata":{}}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-02-04T09:43:32.473356Z","iopub.execute_input":"2024-02-04T09:43:32.473655Z","iopub.status.idle":"2024-02-04T11:15:58.754349Z","shell.execute_reply.started":"2024-02-04T09:43:32.473630Z","shell.execute_reply":"2024-02-04T11:15:58.753174Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='153' max='153' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [153/153 1:31:54, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>1.569700</td>\n      <td>1.293707</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.425300</td>\n      <td>1.125321</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>1.202900</td>\n      <td>1.002538</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.986600</td>\n      <td>0.910008</td>\n    </tr>\n    <tr>\n      <td>125</td>\n      <td>0.871200</td>\n      <td>0.875669</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.824500</td>\n      <td>0.862401</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=153, training_loss=1.1094477597404928, metrics={'train_runtime': 5545.7838, 'train_samples_per_second': 0.442, 'train_steps_per_second': 0.028, 'total_flos': 1.19029468658688e+16, 'train_loss': 1.1094477597404928, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"import gc\nimport torch\n# del model\n\ngc.collect()\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-02-04T11:22:59.928622Z","iopub.execute_input":"2024-02-04T11:22:59.929485Z","iopub.status.idle":"2024-02-04T11:23:00.655245Z","shell.execute_reply.started":"2024-02-04T11:22:59.929428Z","shell.execute_reply":"2024-02-04T11:23:00.654074Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\nfrom peft import PeftModel\nimport torch\n\n# base model\nbase_path = 'microsoft/phi-2'\n\n# adapters: path to folder with adapter_model.safetensors\nadapter_path = 'out/checkpoint-153'\n\n# model dir\nsave_to = 'trained_model'\n\n# load model and tokenizer\nbase_model = AutoModelForCausalLM.from_pretrained(\n    base_path,\n    torch_dtype = torch.bfloat16,\n    device_map = 'auto'\n)\n\ntokenizer = AutoTokenizer.from_pretrained(base_path)\n\n# Add/set tokens same tokens to base model before merging, like we did before training  \ntokenizer.add_tokens([\"<|im_start|>\", \"<PAD>\"])\ntokenizer.pad_token = \"<PAD>\"\ntokenizer.add_special_tokens(dict(eos_token=\"<|im_end|>\"))\n\n# Add ChatML template to tokenizer\ntokenizer.chat_template=\"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\"\n\nbase_model.config.eos_token_id = tokenizer.eos_token_id\n\n# Set a default Generation configuration: Llama precise\ngeneration_config = GenerationConfig(\n    max_new_tokens=100, \n    temperature=0.7,\n    top_p=0.1,\n    top_k=40,\n    repetition_penalty=1.18,\n    do_sample=True,\n    pad_token_id=tokenizer.pad_token_id,\n    eos_token_id=tokenizer.eos_token_id,\n)\n\n# Load LoRA and merge\nmodel = PeftModel.from_pretrained(base_model, adapter_path)\nmodel = model.merge_and_unload()\n\nmodel.save_pretrained(save_to, safe_serialization=True, max_shard_size='4GB')\ntokenizer.save_pretrained(save_to)\ngeneration_config.save_pretrained(save_to)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-02-04T11:24:37.704592Z","iopub.execute_input":"2024-02-04T11:24:37.705021Z","iopub.status.idle":"2024-02-04T11:25:29.975208Z","shell.execute_reply.started":"2024-02-04T11:24:37.704992Z","shell.execute_reply":"2024-02-04T11:25:29.973713Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa0cd61ea23c4c189169b50c250ea32b"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\nimport torch\n# del model\n# del base_model\n\ngc.collect()\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-02-04T11:28:31.997614Z","iopub.execute_input":"2024-02-04T11:28:31.998005Z","iopub.status.idle":"2024-02-04T11:28:32.729900Z","shell.execute_reply.started":"2024-02-04T11:28:31.997973Z","shell.execute_reply":"2024-02-04T11:28:32.728648Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Inference from trained model\n","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\nfrom peft import PeftModel\nimport torch\n\nmodel_path=\"trained_model\"    \nquestion=\"Hello, who are you?\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n        model_path,    \n        torch_dtype=torch.bfloat16,\n        device_map=\"auto\"\n    )\ntokenizer = AutoTokenizer.from_pretrained(model_path) \n\nmessages=[\n    {\"role\": \"user\", \"content\": question}\n]\n        \ninput_tokens = tokenizer.apply_chat_template(\n    messages, \n    add_generation_prompt=True,\n    return_tensors=\"pt\"\n).to(\"cuda\")\n\noutput_tokens = model.generate(input_tokens)\noutput = tokenizer.decode(\n    output_tokens[0][len(input_tokens[0]):],\n    skip_special_tokens=True\n    )               \n\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2024-02-04T11:28:36.058572Z","iopub.execute_input":"2024-02-04T11:28:36.059244Z","iopub.status.idle":"2024-02-04T11:28:44.927241Z","shell.execute_reply.started":"2024-02-04T11:28:36.059213Z","shell.execute_reply":"2024-02-04T11:28:44.926138Z"},"trusted":true},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fba523ba60fa4871beea2a583af8c6d4"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"name":"stdout","text":"I am an AI language model. I don't have a physical form or the ability to ask questions directly from users. However, I can help answer any questions related to my capabilities and functions based on the information provided in the previous messages. If there's anything specific you'd like me to clarify about my abilities as an AI language model, please let me know!\n","output_type":"stream"}]},{"cell_type":"code","source":"def response(question):\n    messages=[\n    {\"role\": \"user\", \"content\": question}\n    ]\n        \n    input_tokens = tokenizer.apply_chat_template(\n        messages, \n        add_generation_prompt=True,\n        return_tensors=\"pt\"\n    ).to(\"cuda\")\n\n    output_tokens = model.generate(input_tokens)\n    output = tokenizer.decode(\n        output_tokens[0][len(input_tokens[0]):],\n        skip_special_tokens=True\n        )               \n\n    return output","metadata":{"execution":{"iopub.status.busy":"2024-02-04T11:29:45.846033Z","iopub.execute_input":"2024-02-04T11:29:45.846515Z","iopub.status.idle":"2024-02-04T11:29:45.854645Z","shell.execute_reply.started":"2024-02-04T11:29:45.846481Z","shell.execute_reply":"2024-02-04T11:29:45.853517Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"response('what is cloud computing?')","metadata":{"execution":{"iopub.status.busy":"2024-02-04T11:30:42.344125Z","iopub.execute_input":"2024-02-04T11:30:42.344836Z","iopub.status.idle":"2024-02-04T11:30:47.558977Z","shell.execute_reply.started":"2024-02-04T11:30:42.344806Z","shell.execute_reply":"2024-02-04T11:30:47.557707Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"'Cloud computing refers to the delivery of various services, including storage, processing power, and software applications over the internet. Instead of relying on local servers or personal computers, users can access these resources remotely through a network connection. This allows for greater flexibility, scalability, and cost-effectiveness compared to traditional on-premises solutions. Some common examples of cloud computing include online email providers like Gmail, file sharing platforms like Dropbox, and virtual private networks (VPNs) that allow secure remote access to'"},"metadata":{}}]},{"cell_type":"code","source":"response('Do you know about OpenAI')","metadata":{"execution":{"iopub.status.busy":"2024-02-04T11:31:33.379421Z","iopub.execute_input":"2024-02-04T11:31:33.380292Z","iopub.status.idle":"2024-02-04T11:31:38.616910Z","shell.execute_reply.started":"2024-02-04T11:31:33.380260Z","shell.execute_reply":"2024-02-04T11:31:38.615622Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"'Yes, I am aware of OpenAI. It is an artificial intelligence research and development company that was founded in 2015 by Elon Musk, Sam Altman, Ilya Sutskever, Greg Brockman, and Shane Legg. The goal of OpenAI is to develop AI systems that can benefit humanity while also ensuring their safety and avoiding any potential risks or negative consequences. They have several projects focused on natural language processing (NLP), computer vision, reinforcement learning, and other areas of AI research'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install --upgrade huggingface_hub --q","metadata":{"execution":{"iopub.status.busy":"2024-02-04T11:35:13.944966Z","iopub.execute_input":"2024-02-04T11:35:13.945375Z","iopub.status.idle":"2024-02-04T11:35:26.847149Z","shell.execute_reply.started":"2024-02-04T11:35:13.945344Z","shell.execute_reply":"2024-02-04T11:35:26.845700Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"execution":{"iopub.status.busy":"2024-02-04T11:35:42.119975Z","iopub.execute_input":"2024-02-04T11:35:42.120400Z","iopub.status.idle":"2024-02-04T11:35:42.155841Z","shell.execute_reply.started":"2024-02-04T11:35:42.120366Z","shell.execute_reply":"2024-02-04T11:35:42.153871Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09091898b7bd4bb3ba836000189dbb20"}},"metadata":{}}]},{"cell_type":"code","source":"model.push_to_hub(\"Aditya685/phi-2_riddles-evolved_epoch3\")\ntokenizer.push_to_hub(\"Aditya685/phi-2_riddles-evolved_epoch3\")","metadata":{"execution":{"iopub.status.busy":"2024-02-04T11:36:07.500987Z","iopub.execute_input":"2024-02-04T11:36:07.501793Z","iopub.status.idle":"2024-02-04T11:38:36.642938Z","shell.execute_reply.started":"2024-02-04T11:36:07.501762Z","shell.execute_reply":"2024-02-04T11:38:36.641955Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ee970b497f74ca78a1d1cb3a2ec9877"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b83ecf4172149768c042c8c1cb458f3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f147ab955aa4216a53c77afc20f497b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"900d016871ea4095ad1e94d7e923a357"}},"metadata":{}},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Aditya685/phi-2_riddles-evolved_epoch3/commit/af30eb0d946f783af978016bf4d2430b5cea312e', commit_message='Upload tokenizer', commit_description='', oid='af30eb0d946f783af978016bf4d2430b5cea312e', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}